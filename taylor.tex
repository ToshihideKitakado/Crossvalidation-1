A well-fitting model results in predicted values close to the reference values, i.e. if $Y_t$ is the variable of interest at time $t$ and ${\hat{Y}_t}$ is it's predicted value then the prediction error $e_t = Y_t - \hat{Y}_t$ should be small.

A commonly used measure is root mean square error (RMSE,~$E^\prime$), the square root of the variance of the residuals and indicates how close the observed data points are to the predicted values i.e.
     
     \begin{equation} {${E^{\prime} = \sqrt{\frac{1}{T} \sum_{t=1}^T e_t^2}}$} \end{equation}

As the square root of a variance it can also be interpreted as the standard deviation of the unexplained variance, lower values indicate better fits. $E^\prime$ is sensitive to outliers, however,and favours forecasts that avoid large deviations from the mean and cannot be used to compare across series.

The best statistical measure to use depends on the objectives of the analysis and using more than one measure can be helpful in providing insight into the nature of observation and process error structures.
For example the correlation ($\rho$) between $Y_y$ and $\bar{Y_y}$ is not affected by the amplitude of the variations, is insensitive to biases and errors in variance, and can be used to compare across seris. $E^{\prime 2}$ and $\rho$ are related by the cosine rule i.e.

  \begin{equation} {$E^{\prime 2} = \sigma_o^2 + \sigma_f^2 - 2\sigma_o\sigma_f\rho$} \end{equation}

 Where the reference set ($o$) are the observations not included in the retrospective assessment and the values (f) are their estimates. 
 
 This means that $E^\prime$, $\rho$ and $\sigma_f$ can be summarised simultaneously in a single diagram \citep{taylor2001summarizing}. Taylor diagrams therefore provide a concise statistical summary of how well patterns match each other and are therefore especially useful for evaluating multiple aspects or in gauging the relative skill of different models \citep{griggs2002climate}.
